{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score,confusion_matrix\n",
    "from imblearn.combine import SMOTETomek\n",
    "overSampler=SMOTETomek()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_parquet('/home/hashmi/Files/DataFolder/ParticleBoxData/DownstreamData.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['track_p']<100e3]\n",
    "data.track_nLHCbIDs=data.track_nLHCbIDs.astype('int')\n",
    "\n",
    "\n",
    "sample=data.sample(frac=0.01,random_state=46)\n",
    "\n",
    "x=sample.drop(['Downstream',],axis=1)\n",
    "y=sample['Downstream'].map({True:1,False:0})\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "\n",
    "x=ss.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,shuffle=True,stratify=y,random_state=29,test_size=0.3)\n",
    "\n",
    "x_train,y_train=overSampler.fit_resample(X=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFun(Dataset):\n",
    "    def __init__(self,x_data,y_data):\n",
    "        self.x_data=x_data\n",
    "        self.y_data=y_data\n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=DataFun(torch.FloatTensor(x_train),torch.FloatTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,input_num,output_num):\n",
    "        super(Network,self).__init__()\n",
    "        self.layer1=nn.Linear(input_num,15)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.layer2=nn.Linear(15,output_num)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.relu1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "lr=0.01\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(params=model.parameters())\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "backward() got an unexpected keyword argument 'requires_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m y_predict \u001b[39m=\u001b[39m model(x_batch)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_batch\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m),y_predict)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=8'>9</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward(requires_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# epoch_loss+=loss.item()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# print(y_batch.unsqueeze(1))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=12'>13</a>\u001b[0m \u001b[39m# print(y_predict.unsqueeze(1))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c4843624431227d/home/hashmi/Files/ParticleBox/Torch/01_Baseline.ipynb#ch0000010vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# print(loss)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: backward() got an unexpected keyword argument 'requires_grad'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epoch+1):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x_batch,y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(x_batch).detach()\n",
    "        loss = criterion(y_batch.unsqueeze(1),y_predict)\n",
    "        loss.backward(requires_grad=True)\n",
    "        optimizer.step()\n",
    "        # epoch_loss+=loss.item()\n",
    "        # print(y_batch.unsqueeze(1))\n",
    "        # print(y_predict.unsqueeze(1))\n",
    "        # print(loss)\n",
    "        break\n",
    "    break\n",
    "    # print(epoch,epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0b5704e0753844c914e694f858654540ae357911934d72da4d907f6643f065e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('remote')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
